{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle example","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain = pd.read_csv(\"C:\\\\Users\\\\szuje\\\\Documents\\\\Y2S2\\\\TML\\\\datasets\\\\mnist-digit-recognizer\\\\train.csv\")\ntest = pd.read_csv(\"C:\\\\Users\\\\szuje\\\\Documents\\\\Y2S2\\\\TML\\\\datasets\\\\mnist-digit-recognizer\\\\test.csv\")\n\nx_train = train.drop('label', axis=1)\ny_train = train['label']\n\nx_train = x_train/255\nx_test = test/255\n\n#rf = RandomForestClassifier(n_estimators=5, max_features=0.5)\n#rf.fit(x_train, y_train)\n#pred = rf.predict(x_test)\n\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\nsvc = SVC()\nsvc.fit(x_train,y_train)\npred=svc.predict(x_test)\n\nID = '1201200641'\nid = np.arange(1,10001)\nd = {'ID':id, 'label':pred}\ndf = pd.DataFrame(data=d)\ndf.to_csv(ID+\".csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lab 9\nTurning class into number","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.datasets import load_iris\n\ndata = load_iris()\nx = data.data\ny = data.target\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(x,y)\npred = knn.predict(x)\n\nprint(\"Accuracy :\", accuracy_score(y,pred))\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.5, random_state=0)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(x_train,y_train)\npred = knn.predict(x_test)\n\nprint(\"Accuracy :\", accuracy_score(y_test,pred))\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test, pred, labels=knn.classes_.tolist()))\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test, pred, labels=knn.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_)\nfig, ax = plt.subplots(figsize=(5,5))\nax.set_title(\"Confusion Matrix\")\ndisp.plot(ax=ax)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt=DecisionTreeClassifier(max_depth=2, min_samples_leaf=4, random_state=0)\ndt.fit(x_train, y_train)\npred = dt.predict(x_test)\n\nprint(\"Accuracy :\", accuracy_score(y_test, pred))\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test, pred, labels=dt.classes_.tolist()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\n\nknn = KNeighborsClassifier(n_neighbors=3)\nbag = BaggingClassifier(knn, n_estimators=20, max_samples=0.5)\nbag.fit(x_train, y_train)\npred = bag.predict(x_test)\n\nprint(\"Accuracy :\", accuracy_score(y_test, pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=20, max_features=0.5)\nrf.fit(x_train, y_train)\npred = rf.predict(x_test)\nprint(\"Accuracy :\", accuracy_score(y_test, pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\ndt=DecisionTreeClassifier(max_depth=2, min_samples_leaf=4, random_state=0)\nada = AdaBoostClassifier(dt, n_estimators=20)\nada.fit(x_train, y_train)\npred=ada.predict(x_test)\nprint(\"Accuracy: \",accuracy_score(y_test,pred))\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LAb 7","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain = pd.read_csv(\"C:\\\\Users\\\\szuje\\\\Documents\\\\Y2S2\\\\TML\\\\datasets\\\\mnist-digit-recognizer\\\\train.csv\")\ntest = pd.read_csv(\"C:\\\\Users\\\\szuje\\\\Documents\\\\Y2S2\\\\TML\\\\datasets\\\\mnist-digit-recognizer\\\\test.csv\")\n\nx_train = train.drop('label', axis=1)\ny_train = train['label']\n\n#rf = RandomForestClassifier(n_estimators=5, max_features=0.5)\n#rf.fit(x_train, y_train)\n#pred = rf.predict(x_test)\n\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\nsvc = SVC()\nsvc.fit(x_train,y_train)\npred=svc.predict(x_test)\n\nID = '1201200641'\nid = np.arange(1,10001)\nd = {'ID':id, 'label':pred}\ndf = pd.DataFrame(data=d)\ndf.to_csv(ID+\".csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GridSearch Example in Lab 10","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.datasets import load_breast_cancer\n\ndata = load_breast_cancer()\nx = data.data\ny = data.target\nprint(x.shape, y.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-26T18:26:31.124135Z","iopub.execute_input":"2023-05-26T18:26:31.124810Z","iopub.status.idle":"2023-05-26T18:26:32.781178Z","shell.execute_reply.started":"2023-05-26T18:26:31.124777Z","shell.execute_reply":"2023-05-26T18:26:32.779944Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"(569, 30) (569,)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2,\n                                                   random_state=0)\n#80*0.25 = 20\nx_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size = 0.25,\n                                                   random_state=0)\n\nprint(x_train.shape)\nprint(x_val.shape)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T18:27:31.161001Z","iopub.execute_input":"2023-05-26T18:27:31.161402Z","iopub.status.idle":"2023-05-26T18:27:31.309882Z","shell.execute_reply.started":"2023-05-26T18:27:31.161373Z","shell.execute_reply":"2023-05-26T18:27:31.308694Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(341, 30)\n(114, 30)\n(114, 30)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nparams = {'n_estimators':[10,20,30], \n         'max_depth':[3,5,7,9],\n         'max_features':[0.5,0.7,1.0]}\n\nrf = RandomForestClassifier()\nclf = GridSearchCV(rf, params, cv=5)\nclf.fit(x_train, y_train)\nprint(\"Best combination: \", clf.best_params_)\n\nprint('Training accuracy', clf.score(x_train, y_train))\nprint('Validation accuracy', clf.score(x_val, y_val))\nprint('Testing accuracy', clf.score(x_test, y_test))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-26T18:27:43.367805Z","iopub.execute_input":"2023-05-26T18:27:43.368190Z","iopub.status.idle":"2023-05-26T18:27:57.634436Z","shell.execute_reply.started":"2023-05-26T18:27:43.368162Z","shell.execute_reply":"2023-05-26T18:27:57.633398Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Best combination:  {'max_depth': 5, 'max_features': 1.0, 'n_estimators': 20}\nTraining accuracy 0.9941348973607038\nValidation accuracy 0.9385964912280702\nTesting accuracy 0.956140350877193\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# [Detecting Missing Value](https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b)","metadata":{}},{"cell_type":"markdown","source":"# LAb 8","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.datasets import fetch_openml\n\nx,y = fetch_openml('mnist_784', version=1, return_X_y=True)\n\nx = x.to_numpy()\nx /= 255\n\nnp.unique(y)\n\nx1 = x[(y=='0')|(y=='1')]\ny1 = y[(y=='0')|(y=='1')]\nprint(x1.shape, y1.shape)\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x1,y1, test_size=0.2, random_state=42)\n\nfrom sklearn.linear_model import Perceptron\np = Perceptron(max_iter=1000, random_state=42)\np.fit(x_train, y_train)\npred = p.predict(x_test)\nprint(\"Training acc:\", p.score(x_train, y_train))\nprint(\"Testing acc:\", p.score(x_test, y_test))\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred, labels=p.classes_.tolist()))\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y_test, pred, labels=p.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=p.classes_)\nfig, ax = plt.subplots(figsize=(4,4))\nax.set_title(\"Confusion Matrix\")\ndisp.plot(ax=ax)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lab 7","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.datasets import load_breast_cancer\n\ndata = load_breast_cancer()\n\nx = data.data\ny = data.target\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=101)\n\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter = 3000)\n\nlr.fit(x_train, y_train)\n\npred = lr.predict(x_test)\n\nfrom sklearn import metrics\n\nprint(\"Accuracy :\", metrics.accuracy_score(y_test,pred))\nprint(\"Precision :\", metrics.precision_score(y_test,pred))\nprint(\"Recall :\", metrics.recall_score(y_test,pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lab 6","metadata":{}},{"cell_type":"code","source":"sns.heatmap(data.isnull(), yticklabels=False, cmap='viridis')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived', hue='Sex', data=data, palette='RdBu_r')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Survived', hue='Pclass', data=data, palette='rainbow')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.boxplot(x='Pclass', y='Age', data=data, palette='winter')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass ==1:\n            return 37\n        elif Pclass == 2:\n            return 29\n       \telse:\n            return 24\n    else:\n        return Age","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age']=data[['Age', 'Pclass']].apply(impute_age, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.isnull(), yticklabels=False, cmap='viridis')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sex = pd.get_dummies(data['Sex'])\nembark = pd.get_dummies(data['Embarked'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Embarked'], axis=1, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([data, sex, embark], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx= data.drop('Survived', axis=1)\ny = data['Survived']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=101)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter=500)\n\nlr.fit(x_train, y_train)\n\npred = lr.predict(x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data.iloc[0:50, 0], data.iloc[0:50, 1], color='red', marker='o', label='Setosa')\nplt.scatter(data.iloc[50:100, 0], data.iloc[50:100, 1], color='green', marker='s', label='Versicolor')\nplt.scatter(data.iloc[100:150, 0], data.iloc[100:150, 1], color='blue', marker='^', label='Virginica')\n\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Sepal Width (cm)')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VRA SVM","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport glob\nimport json\nimport os\nimport ast\nimport numpy as np\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\n\n# import SVC classifier\nfrom sklearn.svm import SVC\nfrom sklearn import svm\n\n# import metrics to compute accuracy (Evulate)\nfrom sklearn.metrics import accuracy_score, confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.decomposition import PCA","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/content/drive/MyDrive/Dataset/angle/raw_features.csv', \n                   converters={'distance': ast.literal_eval,\n                               'angle': ast.literal_eval,\n                               'velocity': ast.literal_eval,\n                               'x': ast.literal_eval,\n                               'y': ast.literal_eval,\n                               'norma_x': ast.literal_eval,\n                               'norma_y': ast.literal_eval,})\n\nx = np.array(data[['distance', 'angle', 'velocity', 'x', 'y', 'norma_x', 'norma_y']].values.tolist(), dtype=object)\ny = data[\"action\"].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder=LabelEncoder()\ny=encoder.fit_transform(y)\ny=to_categorical(y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_samples, train_dims1, train_dims2 = x_train.shape\nx_train = x_train.reshape((train_samples, train_dims1 * train_dims2))\n\ntest_samples, test_dims1, test_dims2 = x_test.shape\nx_test = x_test.reshape((test_samples, test_dims1 * test_dims2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = np.argmax(y_train, axis=1)\ny_test = np.argmax(y_test, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_components = 50\npca = PCA(n_components=n_components)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = pca.fit_transform(x_train)\nx_test = pca.transform(x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': [0.1, 1, 10]}\nsvm_model = SVC()\nsvm_grid = GridSearchCV(svm_model, param_grid, cv=5)\nsvm_grid.fit(x_train, y_train)\n\nprint(\"Best parameters:\", svm_grid.best_params_)\n\nclass_weights = {}\nfor i in range(len(np.unique(y_train))):\n    class_weights[i] = len(y_train) / (len(np.unique(y_train)) * np.bincount(y_train)[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0, 10):\n  clf = svm.SVC(kernel=svm_grid.best_params_['kernel'], C=svm_grid.best_params_['C'], gamma=svm_grid.best_params_['gamma'], class_weight=class_weights)\n\n  train_start = time.time()\n  clf.fit(x_train, y_train)\n  train_end = time.time()\n\n  train_time = train_end - train_start\n  print(f\"Time used to train the model {i}: {train_time} seconds\")\n\n  predict_start = time.time()\n  y_pred = clf.predict(x_test)\n  predict_end = time.time()\n\n  predict_time = predict_end - predict_start\n  print(f\"Time used to make predictions {i}: {predict_time} seconds\") \n\n  accuracy = accuracy_score(y_test, y_pred)\n  print(\"Accuracy:\", accuracy*100, '%')\n\n  report = classification_report(y_test, y_pred, zero_division=1)\n  print(report)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_score=round(clf.score(x_train, y_train),3)\ntest_score=round(clf.score(x_test, y_test),3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def addlabels(x,y):\n    for i in range(len(x)):\n        plt.text(i,y[i],y[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VRA CNN","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport ast\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Dense,Conv1D,Flatten,MaxPool1D\nfrom keras.models import Sequential\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/content/drive/MyDrive/Dataset/angle/raw_features.csv', \n                   converters={'distance': ast.literal_eval,\n                               'angle': ast.literal_eval,\n                               'velocity': ast.literal_eval,\n                               'x': ast.literal_eval,\n                               'y': ast.literal_eval,\n                               'norma_x': ast.literal_eval,\n                               'norma_y': ast.literal_eval,})\n\nx = np.array(data[['distance', 'angle', 'velocity', 'x', 'y', 'norma_x', 'norma_y']].values.tolist(), dtype=object)\ny = data[\"action\"].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_samples, train_dims1, train_dims2 = x_train.shape\nx_train = x_train.reshape((train_samples, train_dims1 * train_dims2))\n\ntest_samples, test_dims1, test_dims2 = x_test.shape\nx_test = x_test.reshape((test_samples, test_dims1 * test_dims2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder=LabelEncoder()\ny_train=encoder.fit_transform(y_train)\ny_train=to_categorical(y_train)\n\ny_test=encoder.fit_transform(y_test)\ny_test=to_categorical(y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{},"execution_count":null,"outputs":[]}]}